{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grayscale image conversion to RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-grsG0LvIesO",
    "outputId": "d0b09958-e55c-468e-b1e1-b2d15e3d6948"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jwLhRphfJeWH"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, Input, UpSampling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pXDMlpn_KipG"
   },
   "outputs": [],
   "source": [
    "#Load the training data\n",
    "X = []\n",
    "for filename in os.listdir('/content/drive/My Drive/gray2rgb/dataset2/train/'):\n",
    "    x = img_to_array(load_img('/content/drive/My Drive/gray2rgb/dataset2/train/'+filename))\n",
    "    x = np.pad(x, [(0, 0), (7,7), (0,0)], mode='mean')\n",
    "    X.append(x)\n",
    "X = np.array(X, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "4z-LjI5PLk43",
    "outputId": "ce6710a5-6159-444d-aa90-ad424a81d06f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1468, 240, 288, 3) (164, 240, 288, 3)\n",
      "240 288\n"
     ]
    }
   ],
   "source": [
    "#Split thw data to training and test\n",
    "frac = int(0.9*len(X))\n",
    "Xtrain = X[:frac]\n",
    "Xtrain = 1.0/255*Xtrain #normalizing the pixels to [-1,1] \n",
    "Xtest = X[frac:]\n",
    "Xtest = 1.0/255*Xtest #normalizing the pixels to [-1,1] \n",
    "\n",
    "print(Xtrain.shape, Xtest.shape)\n",
    "\n",
    "# Changing training image orientation,size etc\n",
    "imgdata = ImageDataGenerator(\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        rotation_range=20,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "\n",
    "# Generate training data\n",
    "batch_size = 60\n",
    "def image_a_b_gen(batch_size):\n",
    "    #img = 0\n",
    "    for batch in imgdata.flow(Xtrain, batch_size=batch_size):\n",
    "        #img+=1\n",
    "        #print(img)\n",
    "        lab = rgb2lab(batch)\n",
    "        X_batch = lab[:,:,:,0]\n",
    "        Y_batch = lab[:,:,:,1:] / 128 #Lab images have intesity -128 to 128\n",
    "        yield (X_batch.reshape(X_batch.shape+(1,)), Y_batch)\n",
    "\n",
    "\n",
    "#preparing testing images\n",
    "Xtest = rgb2lab(Xtest)\n",
    "Xtest = Xtest[:,:,:,0]\n",
    "Xtest = Xtest.reshape(Xtest.shape+(1,))\n",
    "ytest = rgb2lab(1.0/255*X[frac:])\n",
    "ytest = ytest[:,:,:,1:]/128\n",
    "\n",
    "#get size of input image\n",
    "img_rows = X.shape[1]\n",
    "img_cols = X.shape[2]\n",
    "\n",
    "\n",
    "del X\n",
    "print(img_rows, img_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the keras model\n",
    "enc_input = Input(shape=(img_rows,img_cols ,1))\n",
    "model_enc = Conv2D(filters=64, kernel_size=3,  padding='same', activation='relu',strides = 2)(enc_input)\n",
    "model_enc = Conv2D(64, (3, 3), activation='relu', padding='same', strides=2)(model_enc)\n",
    "model_enc = BatchNormalization()(model_enc)\n",
    "model_enc = Conv2D(128, (3, 3), activation='relu', padding='same')(model_enc)\n",
    "model_enc = Conv2D(128, (3, 3), activation='relu', padding='same', strides=2)(model_enc)\n",
    "model_enc = BatchNormalization()(model_enc)\n",
    "model_enc = Conv2D(256, (3, 3), activation='relu', padding='same')(model_enc)\n",
    "model_enc = Conv2D(256, (3, 3), activation='relu', padding='same', strides=2)(model_enc)\n",
    "model_enc = BatchNormalization()(model_enc)\n",
    "model_enc = UpSampling2D(size=(2,2))(model_enc)\n",
    "model_enc = Conv2D(512, (3, 3), activation='relu', padding='same')(model_enc)\n",
    "model_enc = Conv2D(512, (3, 3), activation='relu', padding='same')(model_enc)\n",
    "model_enc = BatchNormalization()(model_enc)\n",
    "model_enc = UpSampling2D(size=(4,4))(model_enc)\n",
    "model_enc = Conv2D(256, (3, 3), activation='relu', padding='same')(model_enc)\n",
    "model_enc = Conv2D(256, (3, 3), activation='relu', padding='same')(model_enc)\n",
    "model_enc = Conv2D(256, (3, 3), activation='relu', padding='same')(model_enc)\n",
    "model_enc = BatchNormalization()(model_enc)\n",
    "model_enc = UpSampling2D(size=(2,2))(model_enc)\n",
    "outputs = Conv2D(2, (1, 1), activation='tanh', padding='same')(model_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training for 30 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 857
    },
    "colab_type": "code",
    "id": "d2Gv_ptjooTk",
    "outputId": "45122ebe-940d-4bb5-e3d0-1df1b339f2c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Cielab\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 240, 288, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 120, 144, 64)      640       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 72, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 60, 72, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 60, 72, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 30, 36, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 36, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 30, 36, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 15, 18, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 18, 256)       1024      \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 30, 36, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 30, 36, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 30, 36, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 30, 36, 512)       2048      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 120, 144, 512)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 120, 144, 256)     1179904   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 120, 144, 256)     590080    \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 120, 144, 256)     590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 120, 144, 256)     1024      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 240, 288, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 240, 288, 2)       514       \n",
      "=================================================================\n",
      "Total params: 7,049,666\n",
      "Trainable params: 7,047,234\n",
      "Non-trainable params: 2,432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#trained for 30 epochs\n",
    "model = Model(inputs = enc_input, outputs=outputs, name='Cielab')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "sWbAo2P0MrhI",
    "outputId": "65b97113-8697-4d5d-dd38-7af5937ba626"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 2/30 [=>............................] - ETA: 1:18 - loss: 0.5809 - accuracy: 0.5700WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 1.1534s vs `on_train_batch_end` time: 2.4644s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 1.1534s vs `on_train_batch_end` time: 2.4644s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - ETA: 0s - loss: 0.2827 - accuracy: 0.5351\n",
      "Epoch 00001: loss improved from inf to 0.28270, saving model to model3.h5\n",
      "30/30 [==============================] - 93s 3s/step - loss: 0.2827 - accuracy: 0.5351\n",
      "Epoch 2/30\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0480 - accuracy: 0.5815\n",
      "Epoch 00002: loss improved from 0.28270 to 0.04803, saving model to model3.h5\n",
      "30/30 [==============================] - 92s 3s/step - loss: 0.0480 - accuracy: 0.5815\n",
      "Epoch 3/30\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0395 - accuracy: 0.5896\n",
      "Epoch 00003: loss improved from 0.04803 to 0.03946, saving model to model3.h5\n",
      "30/30 [==============================] - 92s 3s/step - loss: 0.0395 - accuracy: 0.5896\n",
      "Epoch 4/30\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 0.6020\n",
      "Epoch 00004: loss improved from 0.03946 to 0.03692, saving model to model3.h5\n",
      "30/30 [==============================] - 92s 3s/step - loss: 0.0369 - accuracy: 0.6020\n",
      "Epoch 5/30\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0350 - accuracy: 0.6106\n",
      "Epoch 00005: loss improved from 0.03692 to 0.03497, saving model to model3.h5\n",
      "30/30 [==============================] - 92s 3s/step - loss: 0.0350 - accuracy: 0.6106\n",
      "Epoch 6/30\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0355 - accuracy: 0.6206\n",
      "Epoch 00006: loss did not improve from 0.03497\n",
      "30/30 [==============================] - 92s 3s/step - loss: 0.0355 - accuracy: 0.6206\n",
      "Epoch 7/30\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0321 - accuracy: 0.6146\n",
      "Epoch 00007: loss improved from 0.03497 to 0.03207, saving model to model3.h5\n",
      "30/30 [==============================] - 92s 3s/step - loss: 0.0321 - accuracy: 0.6146\n",
      "Epoch 8/30\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 0.6475\n",
      "Epoch 00008: loss improved from 0.03207 to 0.03179, saving model to model3.h5\n",
      "30/30 [==============================] - 92s 3s/step - loss: 0.0318 - accuracy: 0.6475\n",
      "Epoch 9/30\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0313 - accuracy: 0.6418\n",
      "Epoch 00009: loss improved from 0.03179 to 0.03127, saving model to model3.h5\n",
      "30/30 [==============================] - 92s 3s/step - loss: 0.0313 - accuracy: 0.6418\n",
      "Epoch 10/30\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0280 - accuracy: 0.6415\n",
      "Epoch 00010: loss improved from 0.03127 to 0.02803, saving model to model3.h5\n",
      "30/30 [==============================] - 92s 3s/step - loss: 0.0280 - accuracy: 0.6415\n",
      "Epoch 11/30\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0287 - accuracy: 0.6779\n",
      "Epoch 00011: loss did not improve from 0.02803\n",
      "30/30 [==============================] - 92s 3s/step - loss: 0.0287 - accuracy: 0.6779\n",
      "Epoch 12/30\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0269 - accuracy: 0.6608\n",
      "Epoch 00012: loss improved from 0.02803 to 0.02688, saving model to model3.h5\n",
      "30/30 [==============================] - 92s 3s/step - loss: 0.0269 - accuracy: 0.6608\n",
      "Epoch 13/30\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0283 - accuracy: 0.6610\n",
      "Epoch 00013: loss did not improve from 0.02688\n",
      "30/30 [==============================] - 92s 3s/step - loss: 0.0283 - accuracy: 0.6610\n",
      "Epoch 14/30\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 0.6444\n",
      "Epoch 00014: loss did not improve from 0.02688\n",
      "30/30 [==============================] - 92s 3s/step - loss: 0.0310 - accuracy: 0.6444\n",
      "Epoch 15/30\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0258 - accuracy: 0.6554\n",
      "Epoch 00015: loss improved from 0.02688 to 0.02584, saving model to model3.h5\n",
      "30/30 [==============================] - 92s 3s/step - loss: 0.0258 - accuracy: 0.6554\n",
      "Epoch 16/30\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0260 - accuracy: 0.6607\n",
      "Epoch 00016: loss did not improve from 0.02584\n",
      "30/30 [==============================] - 92s 3s/step - loss: 0.0260 - accuracy: 0.6607\n",
      "Epoch 17/30\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 0.6556\n",
      "Epoch 00017: loss did not improve from 0.02584\n",
      "30/30 [==============================] - 92s 3s/step - loss: 0.0288 - accuracy: 0.6556\n",
      "Epoch 18/30\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 0.6741\n",
      "Epoch 00018: loss improved from 0.02584 to 0.02451, saving model to model3.h5\n",
      "30/30 [==============================] - 92s 3s/step - loss: 0.0245 - accuracy: 0.6741\n",
      "Epoch 19/30\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0251 - accuracy: 0.6567\n",
      "Epoch 00019: loss did not improve from 0.02451\n",
      "30/30 [==============================] - 92s 3s/step - loss: 0.0251 - accuracy: 0.6567\n",
      "Epoch 20/30\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0279 - accuracy: 0.6460\n",
      "Epoch 00020: loss did not improve from 0.02451\n",
      "30/30 [==============================] - 92s 3s/step - loss: 0.0279 - accuracy: 0.6460\n",
      "Epoch 21/30\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 0.6508\n",
      "Epoch 00021: loss did not improve from 0.02451\n",
      "30/30 [==============================] - 92s 3s/step - loss: 0.0248 - accuracy: 0.6508\n",
      "Epoch 22/30\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 0.6630\n",
      "Epoch 00022: loss improved from 0.02451 to 0.02221, saving model to model3.h5\n",
      "30/30 [==============================] - 92s 3s/step - loss: 0.0222 - accuracy: 0.6630\n",
      "Epoch 23/30\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 0.6402\n",
      "Epoch 00023: loss did not improve from 0.02221\n",
      "30/30 [==============================] - 92s 3s/step - loss: 0.0236 - accuracy: 0.6402\n",
      "Epoch 24/30\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0207 - accuracy: 0.6682\n",
      "Epoch 00024: loss improved from 0.02221 to 0.02069, saving model to model3.h5\n",
      "30/30 [==============================] - 92s 3s/step - loss: 0.0207 - accuracy: 0.6682\n",
      "Epoch 25/30\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.6756\n",
      "Epoch 00025: loss improved from 0.02069 to 0.02034, saving model to model3.h5\n",
      "30/30 [==============================] - 92s 3s/step - loss: 0.0203 - accuracy: 0.6756\n",
      "Epoch 26/30\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 0.6578\n",
      "Epoch 00026: loss did not improve from 0.02034\n",
      "30/30 [==============================] - 92s 3s/step - loss: 0.0235 - accuracy: 0.6578\n",
      "Epoch 27/30\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 0.6642\n",
      "Epoch 00027: loss improved from 0.02034 to 0.02013, saving model to model3.h5\n",
      "30/30 [==============================] - 92s 3s/step - loss: 0.0201 - accuracy: 0.6642\n",
      "Epoch 28/30\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0224 - accuracy: 0.6628\n",
      "Epoch 00028: loss did not improve from 0.02013\n",
      "30/30 [==============================] - 92s 3s/step - loss: 0.0224 - accuracy: 0.6628\n",
      "Epoch 29/30\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 0.6643\n",
      "Epoch 00029: loss improved from 0.02013 to 0.01995, saving model to model3.h5\n",
      "30/30 [==============================] - 92s 3s/step - loss: 0.0199 - accuracy: 0.6643\n",
      "Epoch 30/30\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0224 - accuracy: 0.6537\n",
      "Epoch 00030: loss did not improve from 0.01995\n",
      "30/30 [==============================] - 92s 3s/step - loss: 0.0224 - accuracy: 0.6537\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f35a52583c8>"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "batch_size = 30\n",
    "model.compile(optimizer='rmsprop' , loss = 'mse', metrics='accuracy')\n",
    "tensorboard = TensorBoard(log_dir=\"output/third_run\")\n",
    "filepath = \"model3.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "model.fit(image_a_b_gen(batch_size), callbacks=[tensorboard, checkpoint], epochs=30, steps_per_epoch=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "4XEMkSv-Mr-L",
    "outputId": "9df08782-803c-432e-bd0e-b56aefb0da4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 648ms/step - loss: 0.0158 - accuracy: 0.3747\n",
      "[0.015776006504893303, 0.37472599744796753]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(Xtest,ytest,batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nsQuSUWu2V9E"
   },
   "outputs": [],
   "source": [
    "# Load black and white images\n",
    "TestImg = []\n",
    "cnt = 0\n",
    "for filename in os.listdir('/content/drive/My Drive/gray2rgb/dataset2/test/'):\n",
    "  #TestImg.append(img_to_array(load_img('/content/drive/My Drive/gray2rgb/dataset/test/'+filename)))\n",
    "  cnt+=1\n",
    "  x = img_to_array(load_img('/content/drive/My Drive/gray2rgb/dataset2/test/'+filename))\n",
    "  x = np.pad(x, [(0, 0), (7,7), (0,0)], mode='mean')\n",
    "  TestImg.append(x)\n",
    "  if cnt==2:\n",
    "    break\n",
    "\n",
    "TestImg = np.array(TestImg, dtype=float)\n",
    "TestImg = rgb2lab(1.0/255*TestImg)[:,:,:,0]\n",
    "TestImg = TestImg.reshape(TestImg.shape+(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mFAIiP3E2zZH"
   },
   "outputs": [],
   "source": [
    "# Test model\n",
    "output = model.predict(TestImg)\n",
    "output = output * 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "q6dDohv_263C",
    "outputId": "8d36e357-8263-408e-f2c0-fea0ba934cd3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "# Output colorizations\n",
    "for i in range(len(output)):\n",
    "  cur = np.zeros((img_rows,img_cols, 3))\n",
    "  cur[:,:,0] = TestImg[i][:,:,0]\n",
    "  cur[:,:,1:] = output[i]\n",
    "  imsave(\"test\"+str(i)+\".png\", lab2rgb(cur))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained for another 30 epochs using the saved model of previous epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 857
    },
    "colab_type": "code",
    "id": "Bk0lS01mEr1x",
    "outputId": "eb107fb8-5bbf-4a09-dc3b-44d5b5b75097"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Cielab\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 240, 288, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 120, 144, 64)      640       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 72, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 60, 72, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 60, 72, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 30, 36, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 36, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 30, 36, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 15, 18, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 18, 256)       1024      \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 30, 36, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 30, 36, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 30, 36, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 30, 36, 512)       2048      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 120, 144, 512)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 120, 144, 256)     1179904   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 120, 144, 256)     590080    \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 120, 144, 256)     590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 120, 144, 256)     1024      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 240, 288, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 240, 288, 2)       514       \n",
      "=================================================================\n",
      "Total params: 7,049,666\n",
      "Trainable params: 7,047,234\n",
      "Non-trainable params: 2,432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#training the above model for more epochs\n",
    "model1 = Model(inputs = enc_input, outputs=outputs, name='Cielab')\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "lBSUFdxgE_xh",
    "outputId": "3432ffea-6136-49ad-fc0e-ad13d2338c10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 2/74 [..............................] - ETA: 47s - loss: 0.0312 - accuracy: 0.6779WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2896s vs `on_train_batch_end` time: 0.5839s). Check your callbacks.\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 0.6751\n",
      "Epoch 00001: loss improved from inf to 0.02158, saving model to model4.h5\n",
      "74/74 [==============================] - 61s 822ms/step - loss: 0.0216 - accuracy: 0.6751\n",
      "Epoch 2/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 0.6825\n",
      "Epoch 00002: loss improved from 0.02158 to 0.01936, saving model to model4.h5\n",
      "74/74 [==============================] - 59s 799ms/step - loss: 0.0194 - accuracy: 0.6825\n",
      "Epoch 3/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 0.6734\n",
      "Epoch 00003: loss improved from 0.01936 to 0.01888, saving model to model4.h5\n",
      "74/74 [==============================] - 60s 809ms/step - loss: 0.0189 - accuracy: 0.6734\n",
      "Epoch 4/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 0.6794\n",
      "Epoch 00004: loss improved from 0.01888 to 0.01695, saving model to model4.h5\n",
      "74/74 [==============================] - 61s 820ms/step - loss: 0.0170 - accuracy: 0.6794\n",
      "Epoch 5/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.6705\n",
      "Epoch 00005: loss did not improve from 0.01695\n",
      "74/74 [==============================] - 60s 817ms/step - loss: 0.0172 - accuracy: 0.6705\n",
      "Epoch 6/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.6810\n",
      "Epoch 00006: loss improved from 0.01695 to 0.01626, saving model to model4.h5\n",
      "74/74 [==============================] - 61s 819ms/step - loss: 0.0163 - accuracy: 0.6810\n",
      "Epoch 7/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 0.6844\n",
      "Epoch 00007: loss did not improve from 0.01626\n",
      "74/74 [==============================] - 61s 819ms/step - loss: 0.0184 - accuracy: 0.6844\n",
      "Epoch 8/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 0.6829\n",
      "Epoch 00008: loss improved from 0.01626 to 0.01565, saving model to model4.h5\n",
      "74/74 [==============================] - 61s 825ms/step - loss: 0.0157 - accuracy: 0.6829\n",
      "Epoch 9/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.6730\n",
      "Epoch 00009: loss did not improve from 0.01565\n",
      "74/74 [==============================] - 61s 818ms/step - loss: 0.0174 - accuracy: 0.6730\n",
      "Epoch 10/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 0.6804\n",
      "Epoch 00010: loss did not improve from 0.01565\n",
      "74/74 [==============================] - 60s 816ms/step - loss: 0.0169 - accuracy: 0.6804\n",
      "Epoch 11/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.6864\n",
      "Epoch 00011: loss did not improve from 0.01565\n",
      "74/74 [==============================] - 60s 817ms/step - loss: 0.0163 - accuracy: 0.6864\n",
      "Epoch 12/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.6817\n",
      "Epoch 00012: loss improved from 0.01565 to 0.01544, saving model to model4.h5\n",
      "74/74 [==============================] - 60s 817ms/step - loss: 0.0154 - accuracy: 0.6817\n",
      "Epoch 13/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 0.6876\n",
      "Epoch 00013: loss improved from 0.01544 to 0.01412, saving model to model4.h5\n",
      "74/74 [==============================] - 61s 821ms/step - loss: 0.0141 - accuracy: 0.6876\n",
      "Epoch 14/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0145 - accuracy: 0.6886\n",
      "Epoch 00014: loss did not improve from 0.01412\n",
      "74/74 [==============================] - 61s 821ms/step - loss: 0.0145 - accuracy: 0.6886\n",
      "Epoch 15/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 0.6875\n",
      "Epoch 00015: loss did not improve from 0.01412\n",
      "74/74 [==============================] - 61s 819ms/step - loss: 0.0141 - accuracy: 0.6875\n",
      "Epoch 16/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.6828\n",
      "Epoch 00016: loss did not improve from 0.01412\n",
      "74/74 [==============================] - 60s 817ms/step - loss: 0.0150 - accuracy: 0.6828\n",
      "Epoch 17/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 0.6839\n",
      "Epoch 00017: loss did not improve from 0.01412\n",
      "74/74 [==============================] - 60s 817ms/step - loss: 0.0149 - accuracy: 0.6839\n",
      "Epoch 18/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 0.6926\n",
      "Epoch 00018: loss improved from 0.01412 to 0.01386, saving model to model4.h5\n",
      "74/74 [==============================] - 61s 822ms/step - loss: 0.0139 - accuracy: 0.6926\n",
      "Epoch 19/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 0.6960\n",
      "Epoch 00019: loss did not improve from 0.01386\n",
      "74/74 [==============================] - 61s 822ms/step - loss: 0.0149 - accuracy: 0.6960\n",
      "Epoch 20/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0132 - accuracy: 0.6865\n",
      "Epoch 00020: loss improved from 0.01386 to 0.01322, saving model to model4.h5\n",
      "74/74 [==============================] - 61s 822ms/step - loss: 0.0132 - accuracy: 0.6865\n",
      "Epoch 21/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 0.6772\n",
      "Epoch 00021: loss did not improve from 0.01322\n",
      "74/74 [==============================] - 61s 822ms/step - loss: 0.0139 - accuracy: 0.6772\n",
      "Epoch 22/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 0.6909\n",
      "Epoch 00022: loss did not improve from 0.01322\n",
      "74/74 [==============================] - 61s 822ms/step - loss: 0.0133 - accuracy: 0.6909\n",
      "Epoch 23/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 0.6926\n",
      "Epoch 00023: loss did not improve from 0.01322\n",
      "74/74 [==============================] - 61s 822ms/step - loss: 0.0142 - accuracy: 0.6926\n",
      "Epoch 24/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 0.6909\n",
      "Epoch 00024: loss improved from 0.01322 to 0.01277, saving model to model4.h5\n",
      "74/74 [==============================] - 61s 827ms/step - loss: 0.0128 - accuracy: 0.6909\n",
      "Epoch 25/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 0.6954\n",
      "Epoch 00025: loss improved from 0.01277 to 0.01276, saving model to model4.h5\n",
      "74/74 [==============================] - 61s 826ms/step - loss: 0.0128 - accuracy: 0.6954\n",
      "Epoch 26/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 0.6823\n",
      "Epoch 00026: loss did not improve from 0.01276\n",
      "74/74 [==============================] - 61s 828ms/step - loss: 0.0130 - accuracy: 0.6823\n",
      "Epoch 27/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.6921\n",
      "Epoch 00027: loss improved from 0.01276 to 0.01186, saving model to model4.h5\n",
      "74/74 [==============================] - 61s 830ms/step - loss: 0.0119 - accuracy: 0.6921\n",
      "Epoch 28/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.6959\n",
      "Epoch 00028: loss did not improve from 0.01186\n",
      "74/74 [==============================] - 61s 826ms/step - loss: 0.0131 - accuracy: 0.6959\n",
      "Epoch 29/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.6877\n",
      "Epoch 00029: loss did not improve from 0.01186\n",
      "74/74 [==============================] - 61s 825ms/step - loss: 0.0121 - accuracy: 0.6877\n",
      "Epoch 30/30\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.6955\n",
      "Epoch 00030: loss did not improve from 0.01186\n",
      "74/74 [==============================] - 61s 828ms/step - loss: 0.0120 - accuracy: 0.6955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2cd2076940>"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "from tensorflow import keras\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "batch_size = 20\n",
    "model1.compile(optimizer=opt , loss = 'mse', metrics='accuracy')\n",
    "tensorboard = TensorBoard(log_dir=\"output/fourth_run\")\n",
    "filepath = \"model4.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "model1.load_weights('/content/drive/My Drive/gray2rgb/model3.h5')\n",
    "model1.fit(image_a_b_gen(batch_size), callbacks=[tensorboard, checkpoint], epochs=30, steps_per_epoch=74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "NLS0fa4wmm6Y",
    "outputId": "32f35993-9aea-45f7-fe43-73bf7187bd89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 3s 311ms/step - loss: 0.0182 - accuracy: 0.7167\n",
      "[0.01817537285387516, 0.7167033553123474]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "print(model1.evaluate(Xtest,ytest,batch_size=batch_size))\n",
    "\n",
    "# Load black and white images\n",
    "TestImg = []\n",
    "cnt = 0\n",
    "for filename in os.listdir('/content/drive/My Drive/gray2rgb/dataset2/test/'):\n",
    "  #TestImg.append(img_to_array(load_img('/content/drive/My Drive/gray2rgb/dataset/test/'+filename)))\n",
    "  cnt+=1\n",
    "  x = img_to_array(load_img('/content/drive/My Drive/gray2rgb/dataset2/test/'+filename))\n",
    "  x = np.pad(x, [(0, 0), (7,7), (0,0)], mode='mean')\n",
    "  TestImg.append(x)\n",
    "  if cnt==2:\n",
    "    break\n",
    "\n",
    "TestImg = np.array(TestImg, dtype=float)\n",
    "TestImg = rgb2lab(1.0/255*TestImg)[:,:,:,0]\n",
    "TestImg = TestImg.reshape(TestImg.shape+(1,))\n",
    "\n",
    "output = model1.predict(TestImg)\n",
    "output = output * 128\n",
    "\n",
    "# Output colorizations\n",
    "for i in range(len(output)):\n",
    "  cur = np.zeros((img_rows,img_cols, 3))\n",
    "  cur[:,:,0] = TestImg[i][:,:,0]\n",
    "  cur[:,:,1:] = output[i]\n",
    "  imsave(\"test_\"+str(i)+\".png\", lab2rgb(cur))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "grayscale2rgb.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
